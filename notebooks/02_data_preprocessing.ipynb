{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2ab581-d626-4600-abca-86d5f8d1cb63",
   "metadata": {},
   "source": [
    "# Week 2: Data Cleaning & Preprocessing\n",
    "Objective:\n",
    "- Clean the NSL-KDD dataset\n",
    "- Convert categorical features into numerical format\n",
    "- Handle class imbalance awareness\n",
    "- Prevent data leakage\n",
    "- Prepare dataset for model training\n",
    "This notebook prepares the dataset for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a260a7e1-7649-4c3c-85f3-b9eb38c0f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c34a933-1079-42eb-9a4a-ecdf2b412430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "# Ensure data directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(\"data\", \"KDDTrain+.txt\")\n",
    "\n",
    "# If dataset does not exist, download it\n",
    "if not os.path.exists(train_path):\n",
    "    print(\"Dataset not found. Downloading...\")\n",
    "    \n",
    "    url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    with open(train_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Dataset already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7bd999-cd4c-49db-9f52-ffce94472f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (125973, 43)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data\"\n",
    "train_path = os.path.join(DATA_DIR, 'KDDTrain+.txt')\n",
    "\n",
    "COLUMNS = [\n",
    "'duration','protocol_type','service','flag','src_bytes','dst_bytes','land',\n",
    "'wrong_fragment','urgent','hot','num_failed_logins','logged_in',\n",
    "'num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n",
    "'num_shells','num_access_files','num_outbound_cmds','is_host_login',\n",
    "'is_guest_login','count','srv_count','serror_rate','srv_serror_rate',\n",
    "'rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n",
    "'srv_diff_host_rate','dst_host_count','dst_host_srv_count',\n",
    "'dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate',\n",
    "'dst_host_serror_rate','dst_host_srv_serror_rate',\n",
    "'dst_host_rerror_rate','dst_host_srv_rerror_rate','class','difficulty_level'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(train_path, names=COLUMNS)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f859e5eb-4528-499a-86c4-08a9b35a0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows before removal: 0\n",
      "Shape after removing duplicates: (125973, 43)\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.duplicated().sum()\n",
    "print(\"Duplicate rows before removal:\", duplicates)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"Shape after removing duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d1e530-ae17-4ba3-bbcf-14a21582171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_class\n",
      "0    67343\n",
      "1    58630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['binary_class'] = df['class'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "print(df['binary_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9617722-6adf-4db3-a661-1f1fe8eb9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class','binary_class','difficulty_level'], axis=1)\n",
    "y = df['binary_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a720e78c-6373-4f5a-812b-1223491ee707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['protocol_type', 'service', 'flag']\n",
      "Numerical columns: ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object', 'string']).columns\n",
    "numerical_cols = X.select_dtypes(exclude=['object', 'string']).columns\n",
    "print(\"Categorical columns:\", list(categorical_cols))\n",
    "print(\"Numerical columns:\", list(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff1c33a-edce-4529-a14d-cb3138e0b508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (100778, 41)\n",
      "Testing shape: (25195, 41)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintains class distribution\n",
    ")\n",
    "\n",
    "print(\"Training shape:\", X_train.shape)\n",
    "print(\"Testing shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fe0c9a-5846-495b-ab2d-34305e1a7fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training Shape: (100778, 121)\n",
      "Processed Testing Shape: (25195, 121)\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Processed Training Shape:\", X_train_processed.shape)\n",
    "print(\"Processed Testing Shape:\", X_test_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f28a4b2-d6f4-48a0-969d-5bcaba0828f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Shape: (100778, 41)\n",
      "Processed Training Shape: (100778, 121)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Training Shape:\", X_train.shape)\n",
    "print(\"Processed Training Shape:\", X_train_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71844165-2393-4be8-9c0b-793db1579522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/preprocessor.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(preprocessor, \"models/preprocessor.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd737362-8ace-4126-8d45-d42b2d125d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set (%):\n",
      "binary_class\n",
      "0    53.458096\n",
      "1    46.541904\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = y_train.value_counts(normalize=True) * 100\n",
    "print(\"Class distribution in training set (%):\")\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c098c2c-d9a7-4b49-ba20-c47666d03ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python314\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "808cabbf-2541-4aba-9c96-c525aa2bbab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Training Shape: (107748, 121)\n",
      "Resampled Class Distribution:\n",
      "binary_class\n",
      "0    53874\n",
      "1    53874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(\n",
    "    X_train_processed, y_train\n",
    ")\n",
    "\n",
    "print(\"Resampled Training Shape:\", X_train_resampled.shape)\n",
    "print(\"Resampled Class Distribution:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a44fa8a-9932-4979-8fd9-c724a9d7b4f1",
   "metadata": {},
   "source": [
    "## Week 2 Summary\n",
    "- Removed duplicate records to prevent training bias.\n",
    "- Converted multi-class attack labels into binary classification.\n",
    "- Performed stratified train-test split to maintain class balance.\n",
    "- Built a preprocessing pipeline using ColumnTransformer.\n",
    "- Applied scaling to numerical features and encoding to categorical features.\n",
    "- Ensured no data leakage by fitting transformations only on training data.\n",
    "- Applied SMOTE to address class imbalance (training data only).\n",
    "The dataset is now fully prepared for supervised model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fd9b4-082d-4f87-8cd0-9498a38f2e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
